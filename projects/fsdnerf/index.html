<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="This paper discuss how to estimate 3D scene flows from the deformation field used in Deformable NeRF. We derived an analytical equation to calculate the flows without inverting the deformation field. We show applying flow supervion is helpful to improve reconstruction for fast moving objects.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF, Flow supervision for deformable NeRF, FSDNeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Flow Supervision for Deformable NeRF</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Flow Supervision for Deformable NeRF</h1>
          <h2 class="title is-4"> CVPR 2023 Highlight </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://mightychaos.github.io/">Chaoyang Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://researchers.adelaide.edu.au/profile/lachlan.macdonald">Lachlan Ewen MacDonald</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.laszlojeni.com/">Laszlo A. Jeni</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.ca/citations?user=vmAe35UAAAAJ&hl=en">Simon Lucey</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Carnegie Mellon University,</span>
            <span class="author-block"><sup>2</sup>University of Adelaide</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2303.16333.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=-fCMDXOjg-o"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/MightyChaos/fsdnerf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
          <video id="teaser" autoplay muted loop playsinline height="80%">
              <source src="./static/videos/fsdnerf_teaser.mp4"
                      type="video/mp4">
          </video>
      <h2 class="subtitle has-text-centered">
        FSDNeRF enhance deformable NeRF by applying flow supervision to the derformation field.
      </h2>
    </div>
  </div> 
</section>

<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/playground.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/balloon.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/balloon.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/balloon.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">

    
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Deformable neural radiance fields (e.g. <a href="https://nerfies.github.io/">Nerfies</a> , <a href="https://hypernerf.github.io/">HyperNeRF</a>, <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a>, <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a> ) has been a notable technique to represent dynamic scenes and shows plausible space-time view synthesis results. However, the current implementations only warrant success on teleporting-like videos whose camera motions are significantly more rapid than object motions. Quality of their results significantly decrease on videos with more rapid object motions [4]. For example, in the "broom" example above, both Nefies and HyperNeRF show significant artifacts when trained only using a single camera (i.e. the left camera from the stereo camera rig), as oppose to teleporting between the left and right cameras in the original paper of Nerfies.
          </p>
          <p>
            In this work, we conjecture the deficiency of these deformable NeRF-based methods is mainly due to lack of temporal regularization. The community has explored optical flow as an additional cue to help supervise the temporal transitions of other motion representations, such as scene flow fields [<a href=#cite_nsff id='ref_nsff'>4</a>]  and blend skinning fields. However, enforcing flow constraints with respect to a generic backward deformation field as in Nerfies is non-trivial. We propose an elegant solution to enforce flow constraints for deformable NeRFs, without inverting the backward deformation function.
            Our method produces plausible view synthesis result, as well as accurate depth map and motions.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->



  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/flow_eqs.png">
        <h2 class="subtitle has-text-centered">
          FSDNeRF synthesize flow directly using the deformation field.
        </h2>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/playground.mp4"
                  type="video/mp4">
      </video>
        <h2 class="subtitle has-text-centered">
          Flow supervision is critical to reconstruct plausible motion and structure.
        </h2>
      </div>
    </div>
  </div>

  <!-- Paper video. -->
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/watch?v=-fCMDXOjg-o&t=2s"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
</section>


<section class="section">
    <!-- Concurrent Work. -->
    <div class="container is-max-desktop content">
        <h2 class="title is-3">Related Projects</h2>

        <div class="content has-text-justified">
          <p>
            For reconstructing articulated objects such as animals, please see our <a href="https://gengshan-y.github.io/rac-www/">RAC</a> project, which is an extension of previous work <a href="https://banmo-www.github.io/">BANMo</a>.
          </p>
          <p>
            Both <a href="https://gengshan-y.github.io/rac-www/">RAC</a> and this work are built using an efficient SE(3) libarary <a href="https://github.com/MightyChaos/dqtorch">dqtorch</a> which provides faster CUDA extensions for batched (dual) queternion-based operations.
          </p>
          <p>
            There have been works (e.g. <a href="https://www.cis.upenn.edu/~leijh/projects/cadex/pub/cvpr22_cadex_paper.pdf">CaDeX</a>, <a href="https://ustc3dv.github.io/ndr/">NDR</a>) using bijective neural networks to represent bijective deformation field. The derivation of this work is more general and can be applied to any deformation field representation.
          </p>
        </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Wang_2023_CVPR,
      author    = {Wang, Chaoyang and MacDonald, Lachlan Ewen and Jeni, L\'aszl\'o A. and Lucey, Simon},
      title     = {Flow Supervision for Deformable NeRF},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month     = {June},
      year      = {2023},
      pages     = {21128-21137}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is built using the template of <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
